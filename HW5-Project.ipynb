{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">HW 5 Project</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>A Project by-</h2><br>Shobhit Lamba<br>UIN: 655612480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Problem statement:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen to do option 1, which goes as follows-<br>Option 1: You\tare working\tfor\ta\tnon-profit\tthat\tis\trecruiting student\tvolunteers\tto help\twith\tAlzheimer’s\t\n",
    "patients. You\thave\tbeen\ttasked\twith\tpredicting how\tsuitable\ta\tperson\tis\tfor\tthis\ttask\tby\tpredicting\thow\t\n",
    "empathetic\the\tor\tshe\tis.\tUsing\tthe\tYoung\tPeople\tSurvey dataset\n",
    "(https://www.kaggle.com/miroslavsabo/young-people-survey/),\tpredict\ta\tperson’s\t“empathy” on\ta\tscale\t\n",
    "from\t1\tto\t5.\tYou\tcan\tuse\tany\tof\tthe\tother\tattributes\tin\tthe\tdataset\tto\tmake\tthis\tprediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Importing the required libraries</h2><br>\n",
    "All the required functions are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning) # To ignore a DeprecatedWarning caused by VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Data Preprocessing</h2><br>I decided to not do much preprocessing for the data here. I tried doing feature scaling, label and one-hot encoding the columns with categorical values but they did not show enough progress for me to give more time to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Music</th>\n",
       "      <th>Slow songs or fast songs</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Folk</th>\n",
       "      <th>Country</th>\n",
       "      <th>Classical music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Metal or Hardrock</th>\n",
       "      <th>...</th>\n",
       "      <th>Shopping centres</th>\n",
       "      <th>Branded clothing</th>\n",
       "      <th>Entertainment spending</th>\n",
       "      <th>Spending on looks</th>\n",
       "      <th>Spending on gadgets</th>\n",
       "      <th>Spending on healthy eating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Number of siblings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Music  Slow songs or fast songs  Dance  Folk  Country  Classical music  \\\n",
       "0    5.0                       3.0    2.0   1.0      2.0              2.0   \n",
       "1    4.0                       4.0    2.0   1.0      1.0              1.0   \n",
       "2    5.0                       5.0    2.0   2.0      3.0              4.0   \n",
       "3    5.0                       3.0    2.0   1.0      1.0              1.0   \n",
       "4    5.0                       3.0    4.0   3.0      2.0              4.0   \n",
       "\n",
       "   Musical  Pop  Rock  Metal or Hardrock         ...          \\\n",
       "0      1.0  5.0   5.0                1.0         ...           \n",
       "1      2.0  3.0   5.0                4.0         ...           \n",
       "2      5.0  3.0   5.0                3.0         ...           \n",
       "3      1.0  2.0   2.0                1.0         ...           \n",
       "4      3.0  5.0   3.0                1.0         ...           \n",
       "\n",
       "   Shopping centres  Branded clothing  Entertainment spending  \\\n",
       "0               4.0               5.0                     3.0   \n",
       "1               4.0               1.0                     4.0   \n",
       "2               4.0               1.0                     4.0   \n",
       "3               4.0               3.0                     3.0   \n",
       "4               3.0               4.0                     3.0   \n",
       "\n",
       "   Spending on looks  Spending on gadgets  Spending on healthy eating   Age  \\\n",
       "0                3.0                    1                         3.0  20.0   \n",
       "1                2.0                    5                         2.0  19.0   \n",
       "2                3.0                    4                         2.0  20.0   \n",
       "3                4.0                    4                         1.0  22.0   \n",
       "4                3.0                    2                         4.0  20.0   \n",
       "\n",
       "   Height  Weight  Number of siblings  \n",
       "0   163.0    48.0                 1.0  \n",
       "1   163.0    58.0                 2.0  \n",
       "2   176.0    67.0                 2.0  \n",
       "3   172.0    59.0                 1.0  \n",
       "4   170.0    59.0                 1.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file using pandas\n",
    "data = pd.read_csv(\"responses.csv\")\n",
    "# Removing the rows that do not have any value for 'Empathy' column\n",
    "data = data[np.isfinite(data['Empathy'])]\n",
    "# Filling the missing values in the csv file with the mean of the column\n",
    "data = data.fillna(data.mean())\n",
    "# Removing the columns that do not have numerical values\n",
    "data = data.select_dtypes(exclude = [object])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Separating X and y:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Empathy'].values\n",
    "X = data.drop('Empathy', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Learning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first split the data into train/dev/test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using feature selectors to find the best possible features\n",
    "# relevant to out learning purpose. For now, let's assume 10 features gives\n",
    "# the best results. We will automate the process later and find\n",
    "# the optimal value for it later on when we apply our final model.\n",
    "X_new = SelectKBest(chi2, k = 10).fit_transform(X, y)\n",
    "\n",
    "# Splitting the data into train, dev and test datasets\n",
    "# approximately in the ratio of 60:20:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Running a baseline classifier on the training data and validating it with dev set. The models being used are:<br>1. GausianNB<br>2. MultinomialNB<br>3. K-Nearest Neighbors<br>4. Decision trees<br>5. Multi Layer Perceptron</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39751552795031053"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Gaussian Naive Bayes\n",
    "classifier = GaussianNB()\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "predictions1 = classifier.predict(X_val)\n",
    "accuracy_score(y_val, predictions1)\n",
    "# ~39% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37267080745341613"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Multinomial Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "predictions2 = classifier.predict(X_val)\n",
    "accuracy_score(y_val, predictions2)\n",
    "# ~37% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40372670807453415"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using K-Nearest Neighbors\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "predictions3 = classifier.predict(X_val)\n",
    "accuracy_score(y_val, predictions3)\n",
    "# ~40% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.422360248447205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Decision Trees\n",
    "classifier = tree.DecisionTreeClassifier(criterion='entropy', \n",
    "                                         splitter='best',\n",
    "                                         max_depth=2, min_samples_split=2, \n",
    "                                         min_samples_leaf=1, \n",
    "                                         min_weight_fraction_leaf=0.0, \n",
    "                                         max_features=None, \n",
    "                                         random_state=None, \n",
    "                                         max_leaf_nodes=None, \n",
    "                                         min_impurity_decrease=0.0, \n",
    "                                         min_impurity_split=None)\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "predictions4 = classifier.predict(X_val)\n",
    "accuracy_score(y_val, predictions4)    \n",
    "# ~42% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.391304347826087"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Multi Layer Perceptron\n",
    "classifier = MLPClassifier(solver = 'lbfgs', alpha = 1e-5,\n",
    "                         hidden_layer_sizes = (5, 5), random_state = 1)\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "predictions5 = classifier.predict(X_val)\n",
    "accuracy_score(y_val, predictions5)    \n",
    "# ~39% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 categories for classification in \"Empathy\", and a randomized function would at best give 20% accuracy. It can be assumed that the baseline classifiers are performing fairly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>My Model:</h2><br>For my model, I trained 4 more models in addition to the ones mentioned above. These are SVM, Random Forest, AdaBoost and Logistic Regression and did applied Bagging to all except AdaBoost and Random Forest classifiers. Finally I stacked them up with a Voting classification ensemble using Hard Vote ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43478260869565216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "clf1 = MultinomialNB()\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf1 = BaggingClassifier(clf1)\n",
    "    \n",
    "# Multi-layer Perceptron\n",
    "clf2 = MLPClassifier(solver = 'lbfgs', alpha = 1e-2,\n",
    "                     hidden_layer_sizes = (25, 20), random_state = 1)\n",
    "clf2 = clf2.fit(X_train, y_train) \n",
    "clf2 = BaggingClassifier(clf2)\n",
    "   \n",
    "# SVC\n",
    "clf3 = SVC(C = 1.5)\n",
    "clf3 = clf3.fit(X_train, y_train)\n",
    "clf3 = BaggingClassifier(clf3)\n",
    "   \n",
    "# Decision tree\n",
    "clf4 = tree.DecisionTreeClassifier(criterion='entropy', splitter='best',\n",
    "                                   max_depth=2, min_samples_split=2, \n",
    "                                   min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                   max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, min_impurity_split=None)\n",
    "clf4 = clf4.fit(X_train, y_train)\n",
    "clf4 = BaggingClassifier(clf4)\n",
    "   \n",
    "# Random Forest\n",
    "clf5 = RandomForestClassifier(max_depth = 5, random_state = 0)\n",
    "clf5 = clf5.fit(X_train, y_train)   \n",
    "  \n",
    "# KNN\n",
    "clf6 = KNeighborsClassifier(n_neighbors = 3)\n",
    "clf6 = clf6.fit(X_train, y_train)\n",
    "clf6 = BaggingClassifier(clf6)\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "clf7 = GaussianNB()\n",
    "clf7 = clf7.fit(X_train, y_train)\n",
    "clf7 = BaggingClassifier(clf7)\n",
    "    \n",
    "# AdaBoost Classifier\n",
    "clf8 = AdaBoostClassifier(n_estimators = 100)\n",
    "clf8 = clf8.fit(X_train, y_train)\n",
    "  \n",
    "# Logistic Regression\n",
    "clf9 = LogisticRegression(random_state=1)\n",
    "clf9 = clf9.fit(X_train, y_train)\n",
    "clf9 = BaggingClassifier(clf9)\n",
    "   \n",
    "# Soft Vote ensemble\n",
    "clf = VotingClassifier(estimators = [('mnb', clf1), ('mlp', clf2), ('svc', clf3), \n",
    "                                     ('dt', clf4), ('rf', clf5), ('knn', clf6), \n",
    "                                     ('gnb', clf7), ('ab', clf8), ('lr', clf9)], voting = 'hard')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "ensembled_accuracy = clf.predict(X_val)  \n",
    "accuracy_score(y_val, ensembled_accuracy)    \n",
    "# 43-45% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for test data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44776119402985076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = clf.fit(X_train, y_train)\n",
    "ensembled_accuracy = clf.predict(X_test)  \n",
    "accuracy_score(y_test, ensembled_accuracy)\n",
    "# ~43% accuracy with 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ensembling all those methods gave us a stable and better performance than just using a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tuning the number of features selected</h2><br>Now we need to find out the optimal number of features needed to be used in training to get the best results. <br><br>For this, we'll need to convert our ensemble model into a function and loop over it with a different value of k in feature_selection and finding out a k which gives the highest accuracy. This k will be used for the final training and to make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that runs my model and returns the accuracy after validation\n",
    "def ensemble(X_train, X_test, y_train, y_test):\n",
    "    # Multinomial Naive Bayes\n",
    "    clf1 = MultinomialNB()\n",
    "    clf1 = clf1.fit(X_train, y_train)\n",
    "    clf1 = BaggingClassifier(clf1)\n",
    "    \n",
    "    # Multi-layer Perceptron\n",
    "    clf2 = MLPClassifier(solver = 'lbfgs', alpha = 1e-2,\n",
    "                         hidden_layer_sizes = (25, 20), random_state = 1)\n",
    "    clf2 = clf2.fit(X_train, y_train) \n",
    "    clf2 = BaggingClassifier(clf2)\n",
    "    \n",
    "    # SVC\n",
    "    clf3 = SVC(C = 1.5)\n",
    "    clf3 = clf3.fit(X_train, y_train)\n",
    "    clf3 = BaggingClassifier(clf3)\n",
    "    \n",
    "    # Decision tree\n",
    "    clf4 = tree.DecisionTreeClassifier(criterion='entropy', splitter='best',\n",
    "                                       max_depth=2, min_samples_split=2, \n",
    "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                       max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "                                       min_impurity_decrease=0.0, min_impurity_split=None)\n",
    "    clf4 = clf4.fit(X_train, y_train)\n",
    "    clf4 = BaggingClassifier(clf4)\n",
    "    \n",
    "    # Random Forest\n",
    "    clf5 = RandomForestClassifier(max_depth = 5, random_state = 0)\n",
    "    clf5 = clf5.fit(X_train, y_train)   \n",
    "    \n",
    "    # KNN\n",
    "    clf6 = KNeighborsClassifier(n_neighbors = 3)\n",
    "    clf6 = clf6.fit(X_train, y_train)\n",
    "    clf6 = BaggingClassifier(clf6)\n",
    "    \n",
    "    # Gaussian Naive Bayes\n",
    "    clf7 = GaussianNB()\n",
    "    clf7 = clf7.fit(X_train, y_train)\n",
    "    clf7 = BaggingClassifier(clf7)\n",
    "    \n",
    "    # AdaBoost Classifier\n",
    "    clf8 = AdaBoostClassifier(n_estimators = 100)\n",
    "    clf8 = clf8.fit(X_train, y_train)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    clf9 = LogisticRegression(random_state=1)\n",
    "    clf9 = clf9.fit(X_train, y_train)\n",
    "    clf9 = BaggingClassifier(clf9)\n",
    "    \n",
    "    # Soft Vote ensemble\n",
    "    clf = VotingClassifier(estimators = [\n",
    "            ('mnb', clf1), ('mlp', clf2), ('svc', clf3), ('dt', clf4), ('rf', clf5), ('knn', clf6), ('gnb', clf7), ('ab', clf8), ('lr', clf9)],\n",
    "           voting = 'hard')\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    \n",
    "    return(accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a function that calls ensemble() defined above over the training and validation data and returns the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns validation accuracy\n",
    "def runValidation(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "    ensembled = ensemble(X_train, X_val, y_train, y_val)                                                                                                                                                                   \n",
    "    #print(ensembled)\n",
    "    return ensembled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we write a simple loop to call runValidation() and store all accuracies in a list. The position of the highest accuracy in the array will be the value of k, i.e. the number of features to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "0.4968944099378882\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "\n",
    "for i in range(1,20): # Taking steps of 5\n",
    "    X_new = SelectKBest(chi2, k = i * 5).fit_transform(X, y)\n",
    "    accuracy.append(runValidation(X_new, y))\n",
    "      \n",
    "best_accuracy_loc = accuracy.index(max(accuracy))+ 1 \n",
    "print(best_accuracy_loc * 5) # Variable value for k\n",
    "print(max(accuracy)) # Validation accuracy ~50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the trends followed by accuracy with increase in number of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD5CAYAAADWfRn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl81PW99/3XJ3sCCSFkAZIZQbYEXFBDtG4goF2OYnvUQuz1aHudXrXaejz3udvrPu11t2rXu8e2V9u72sVuxy6idlOqtlYCuLMEUBNIWGQJSSAJJGSD7J/rj5mEIUwyk2TWzOf5eORBZuY3M98Izie/3/v7+X5FVTHGGGNGExfuARhjjIl8ViyMMcb4ZMXCGGOMT1YsjDHG+GTFwhhjjE9WLIwxxvhkxcIYY4xPViyMMcb4ZMXCGGOMTwnBfHER+QDwQyAe+IWqfnvY458EvgPUue96VFV/4X7sE8CX3fd/Q1WfGO29srOzdc6cOYEbvDHGxICdO3eeVNUcX8cFrViISDzwGHAzUAvsEJENqrp32KFPq+r9w56bBTwEFAMK7HQ/t2Wk95szZw7l5eUB/RmMMWayE5Gj/hwXzMtQJcBBVT2kqj3AU8Dtfj73/cDLqtrsLhAvAx8I0jiNMcb4EMxikQ8c87hd675vuDtE5F0R+aOIOMbyXBG5R0TKRaS8qakpUOM2xhgzTDCLhXi5b/gSt38F5qjqZcBGYDCX8Oe5qOrjqlqsqsU5OT4vuRljjBmnYBaLWsDhcbsAqPc8QFVPqWq3++bPgav8fa4xxpjQCWax2AEsEJG5IpIErAM2eB4gIrM8bq4BqtzfvwTcIiLTRWQ6cIv7PmOMMWEQtNlQqtonIvfj+pCPB36lqntE5GtAuapuAB4QkTVAH9AMfNL93GYR+TquggPwNVVtDtZYjTHGjE4my055xcXFalNnjTFmbERkp6oW+zouqE15xhgTaLUtZ/hDeS0T/UW3aFYGH7x0lu8DDWDFwhgTZb770j6efbse8TZn0k+qkJIYx/uXzCQubgIvFEOsWBhjokZLZw8vVp7gE++7iK/efsm4X+e3W4/ylWcraeroJi8jJYAjnLxsIUFjTNT4065aevoGKL3aOaHXcWalAVDTfCYQw4oJViyMMVFBVVm/vYYrnZkUzsyY0GsNFYtTViz8ZcXCGBMVdhxp4b2mTkpLJnZWAZCfmYqInVmMhRULY0xUWL+9hvSUBG69bPaEXyspIY7Z01I5ZsXCb1YsjDER7/SZHl6oOM5HrsgnNSk+IK/pyEq1M4sxsGJhjIl4f9pV5wq2A3AJapAzK82KxRhYsTDGRLTBYPsKZyZFsyYWbHtyZqXR2N7N2Z7+gL3mZGbFwhgT0cqPtnCwsSOgZxUADveMqNoWO7vwhxULY0xEW7+thvTkBG69LLBLc1ivxdhYsTDGRKzTZ3p4vuI4H74in7SkwC44YcVibKxYGGMi1p+DEGwPypqSxJSkeCsWfrJiYQLuWPMZ9ta3hXsYJsoNBttLHZksnh24YHuQiODISrMubj9ZsTAB1d3Xzyd+tZ2P/WIrXb02y8SM386jLRxo7ODuIJxVDLpohk2f9ZcVCxNQv3z9MIdOdtJyppeX9pwI93BMFHtyew1TkxO49fLg7Tkx2GsxWTaBCyYrFiZg6k6f5UdlB7l5cR7OrDTWb68J95BMlGo908sL7x7nw1fMDniw7cmZlUZ33wBN7d1Be4/JwoqFCZhvvrAXRXnotsWsK3Gw9VAzh5o6wj0sE4X+vLuW7iAF254cNiPKb1YsTEC8dqCJFytO8LkV8ymYnsadVxWQECd2dmHGbDDYvrxgGktmTwvqe9n0Wf9ZsTAT1tM3wEMb9nDRjDQ+fePFAOSmp3Dz4jz+uLOW7j4Luo3/dtW0sL+hg7snuMGRP/Kn21Ll/rJiYSbsl68f5lBTJw+vWUJK4rkVQUtLnO6guyGMozPR5sltx1zBdgCWIvclOSGeWRkpViz8YMXCTEj96bP8aNMBbl6cx02Lcs977Pr52TiyUlm/zS5FGf+0nunl+XfruX3pbKYkBy/Y9uTISrN9LfxgxcJMyDdfqKJ/QHnw1sUXPBYXJ6xb5uStQ6cs6DZ++UuIgm1PtlS5f6xYmHF7/cBJXqg4zmdXzB+aVTLcXcWuoPupHcdCPDoTbVzB9jEuK5jGJfnBDbY9ObPSaGjrtiZSH6xYmHFxhdqVOLPS+Mzyi0c8Ljc9hdVFFnQb33bVnGZfQ3tQO7a9cc6wpcr9YcXCjMuv3zjMe02dPLxm8XmhtjelVztp7uzhHxZ0m1Gs317DlKR4brs8+MG2J+u18I8VCzNmx1vP8sOyA6wuymVlYZ7P42+Yn03B9FTruTAjaj3rDravyA9ZsD1oqNfCFhQclRULM2aDofZDty3x6/i4OKG0xMmb753i8MnOII/ORKNnd9fR1TsQ8ktQADOmJJGWFE9N89mQv3c0sWJhxuTNgyd5/t3j3Ldi3oihtjd3XVVAfJzwlJ1dmGEGO7YvzQ9tsD1IRGxGlB+sWBi/9fQN8OCGPTiyUrl3+bwxPTc3I4XVRbn8wYJuM8zuY6epPtEe0umywzmy0qhptrPe0VixMH77rzcPc7Cxg4duXeIz1PamtMQVdL+814Juc876ba5ge83S0Abbnmypct+sWBi/nGjt4ocbD7CqMJfVi32H2t7csCCH/EwLus05bV29/PXdetYszWdqiINtTxfNSKOrd4CmDluqfCRWLIxfvvliFb1jCLW9iY8TSkscvHHwFEcs6DaEN9j2NJi/2bIfI7NiYXx6872T/PWdeu5dPm+ogWm87ip2uIJu6+iOearKk9tquCQ/g0sLQh9se7Klyn2zYmFG1ds/wEPP7aFgeiqfXTG2UNubvIwUVhXm8sedx+jpGwjACE20ejsCgu1B+ZnupcpP2fTZkQS1WIjIB0Rkn4gcFJEvjnLcnSKiIlLsvp0oIk+ISIWIVInIl4I5TjOyJ948woHGDh66bXyhtjelVzs52WFBd6xbv72GtKR4bl+aH+6hkJIYz0xbqnxUQSsWIhIPPAZ8EFgMlIrIBUuTikg68ACwzePuu4BkVb0UuAr4jIjMCdZYjXcNbV18/+X93LQoh9VFub6f4KcbLeiOeW1dvfz1nePcvnR2WINtT7ZU+eiCeWZRAhxU1UOq2gM8Bdzu5bivA48AXR73KTBFRBKAVKAHaAviWI0X33qxit5+V6gtIgF73fg4Yd0yB68fPMnRUxZ0x6Lndtdxtrc/Ii5BDbLGvNEFs1jkA54pZq37viEicgXgUNXnhz33j0AncByoAb6rqs1BHKsZZuuhUzz3dj33Lr+YOdlTAv76FnTHLlXl99tqWDI7g0vD0LE9EmdWGifaumyp8hEEs1h4+1V0qONFROKA7wOf93JcCdAPzAbmAp8XkQvWwRaRe0SkXETKm5qaAjNqQ2//AA8+V0l+Zir3rZgflPeYOS2FlYW5/KHcgu5Y805t61CwHcgz1okanBFV22IhtzfBLBa1gMPjdgFQ73E7HbgE2CIiR4BrgA3ukPtu4O+q2quqjcAbQPHwN1DVx1W1WFWLc3JygvRjxJ4n3jzC/oYOHrxtMalJgQm1vbm7xBV0b6yyoDuWrN82GGyHr2PbG+u1GF0wi8UOYIGIzBWRJGAdsGHwQVVtVdVsVZ2jqnOArcAaVS3HdelppbhMwVVIqoM4VuPW2NbFDzYeYPnCHG4ZZ6e2v25caEG3v872TI5LI+1dvWx4p541l88mPSUx3MM5j/VajC5oxUJV+4D7gZeAKuAZVd0jIl8TkTU+nv4YMBWoxFV0fq2q7wZrrOacX7x+mO6+fh5eE9hQ25v4OGHtMgevHThpewmMorG9i6u+8TIPrN8d9dfTX6w4ztneftZFULA9KHtqEqmJ8VYsRhDUPgtVfVFVF6rqPFX9pvu+B1V1g5djV7jPKlDVDlW9S1WXqOpiVf1OMMdpztl1tIXLCzKZG4RQ25uPFjuIE3hqh51djGR3zWnO9PSz4Z161j6+lca2Lt9PilAv720kPzOVy8Pcse2NLVU+OuvgNkP6B5Q99W0h3VPAFXTn8Ux5Lb39FnR7U1nXSnyc8MN1S9l/op3bH3uDyrrWcA9rzLp6+3n9YBOri3IjKtj25MhKs7PcEVixMEMONXVwtrc/5NMZ777awcmObjZaR7dXFXWtLMidyu1L8/njfe8D4K6fvsXfK4+HeWRj89Z7p+jqHWBlUXCzsImwpcpHZsXCDHm31vXbaqgXdVu+MJdZ01J40oLuC6gqFbWtQ2d7S2ZP47n7r2PRzHTu/d0uHtt8MGo+2DZWNTAlKZ5rLs4K91BG5MxK5WxvPyc7esI9lIhjxcIMqahrJTUxnnk5U0P6vp5Bt01bPN/x1i5Odfacd7aXm57CU/dcw+1LZ/Odl/bx70+/HfHBt6qyqbqRGxbkkJwQvOnYE3XRDFdWZ7nFhaxYmCGVda0snp1BfFzoryevXWZBtzcVdd7P9lIS4/nB2qV84ZaFPPt2PaU/30pje+QG33uPt3G8tYuVAVxjLBis12JkViwMcC7cDtfyC7OmpbKyMNeC7mEGw+3FszIueExEuH/lAn7ysSupPt7Ohx99g731kbmEWllVIyKwsjCyi0XB9FTAziy8sWJhgPCF255KS5w0tXdTZh3dQwbD7dGWh//gpbP4w73vY0Dhzp++yUt7ToRwhP4pq2pgqSOT7KnJ4R7KqGyp8pFZsTDAyJc7Qmn5whx30G2LC4LrOn9lXatfU5kvyZ/GhvuvY0FeOvf+bic/3hI5wXdjexfv1LayKsLPKgZZr4V3ViwMEL5w21NCfBwfLXbw2oEmu2YMnGjr4mRHj99ne7kZKTx9zzXcetlsHvn7Pj7/zDt094U/+N5c3QjAqgieMuvJ9rXwzoqFAcIbbntau8yBYEE3QIV7KvNYmiRTEuP5/9ct5f++eSF/3l3H3T/fxsmO7mAN0S8bq1xd24Uz08M6Dn/ZUuXeWbEwYQ+3Pc3OTOWmRbn8wYJuKutaiRO8htujEREeWLWAH3/sSvbUt3L7o29QdTw8wXdXbz+vHzjJysLI7doezjkjFVWoO21LlXuyYmE4fLKDMz39IV3mYzSlJU4a27spq2oM91DCyhVup497mfgPXTqLP3zmWvoGBrjjJ2+GZc/ztw6d4mxvP6sifMqsJ1t91jsrFuZc53aEFIsVi3KYmZES00uXqyoVfobbo7m0YBob7r+e+blTuee35ew4EtoNJ8uqGkhLiueai2eE9H0nwnotvLNiYaioayUlMY55OaFZadaXhPg4PrrMwasxHHSfC7fHdgnKm7wMV8f3tNREnnjzyMQH5ydVZVNVI9fPzx516m+kyZmaTEpinC0oOIwVC+MKt2dlkBAfOf8c1rmD7mfKY3MabUWA1+lKS0rgjisLeGnPiZAF3lXH26lv7WJ1lMyCGmRLlXsXOZ8OJiwiKdz2NDszlRWLcnl6xzH6YjDoPhduB+7vpbTEQW+/8qedtQF7zdEMNleuKIy+LY+tWFzIikWMGwy3Ly3IDPdQLjAUdFfHXtA90XDbm/m56ZTMyWL99pqQNOyVVTdyuSOT3PSUoL9XoDlsqfILWLGIcUOd2xF2ZgFw06Ic8jKSYy7odoXbwdmEqvRqB0dOneGtQ6cC/tqemtq7eaf2NKujpGt7OGdWGmd6+jnVaUuVD7JiEeMqatsiKtz2lBAfx9piB6/sb6K2JXYuCTS0dXOyozsg4fZwH7xkFtNSE1kf5CVVNu9rRJWIX2V2JDZ99kJWLGJcJIbbntaWOAF4ZkfsBN3BXKcrJTGeO64s4O+VxzkVxKC7rKqB2dNSxtxQGCmcNn32ApH5CWFCYmBA2VPfGpGXoAblZ6ayYmEOT5fHTtBdEYRw29NQ0L0rOEF3V28/rx04ycoI3mvbl8FeC5s+e44Vixh26GQnnRHUuT2S0hInDW3dbIqRoLuyrpX5uVMDGm57WpCXzrI501m//VhQAtxth5s509PPqsLomjLrKSUxnryMZLsM5cGKRQyrjIBlyf2xsjCX3PTYCLpVlXdrJ9657UtpiZPDJzvZeijwHd1lVQ2kJsbzvnnR07XtjU2fPZ8Vixj2bq2rc3t+GJcl90dCfBxrlznYsr9p0i/udi7cDm6x+NCls8hISQh4AVZVyqoauS7Kura9saXKz2fFIoZV1rVSFMHhtqe1yxwAPD3Jg+5QTWVOSYznn68s4O+VJ2gO4PTQfQ3t1J0+y+oonQXlyZmVxvG2rojYEyQSRP6nhAmKaAi3PRVMT2P5whye3lEzqYPuoXB7dvBnEd19tZOe/oGAdnQPrhQc6Xtt+8OZleZaqrxlcp/N+suKRYwaDLejpVjAuaB7876mkLxfT98AH//V9pBO2x0Mt9OSEoL+Xgvz0im+aHpAO7o3VjVwWcE0cjOir2t7OOu1OJ8VixgVLeG2p1AH3b9+4zCv7m/it1uPhuT9gIAsSz4WpSVODp3sZNvhiQfdJzu6efvY6aieBeXJei3OZ8UiRg0uSx7p4banRPce3Vv2NQY96D7R2sUPyw6QmhhPRV0rDW1dQX0/gIa2Lpragx9ue/qny1xB95PbJl6AN1e7urajaaOj0eSkJ5OcEGdnFm5WLGJURRSF257WLnOgBL+j+5svVtE3oPxw3VKAkPR4VIRhE6pABt1lVY3MzEhhSQjyllCwpcrPF12fFCYgBgaUvRG4LLk/HFlp3LggJ6hLl7/53kn++k499y2fx82L88jPTB1abjuYQhlueyotcQXdf55AR3d3Xz+vHWiK6q5tb5xZaRy1Lm7AikVMOnyqk47uvojv3B5JaYmTE21dbAlC0N3bP8BDz+3BkZXKfSvmISKsLsrl9YMn6eoN7hTKyrpW5uWEJtz2tGhmOlddNJ0nJxB0bzvUTGdP/6SYMutpsNfCliq3YhGTKiN4WXJ/rCrKJSdIQfd/vXGEA40dPHTrkqGmspVFeXT1DvDmeycD/n6e3q0L31Tm0hInh5o62T7OoLusqoGUxDiunZcd4JGFlzMrjc6e/oD2okQrKxYx6N3aVpIT4liQGz3htidX0F3A5n2N1Acw6G5o6+IHG/ezsjCX1YvPzei55uIspiTFs7EqeLnFYLgdrrO9f7p0FukpCTw5jgKsqpRVR99e2/6w6bPn+CwWInK/iEwPxWBMaERruO1p3TKnK+gO4B7d33yhit4B5aHbFp93f3JCPDcsyGFTVWPQLkcEes/tsUpNiuefr8jnbxUnaBnjb9H7GzqobTnLykkyZdaTc4YVi0H+fFrMBHaIyDMi8gGZTOlVDIrmcNuTIyuNGwIYdL/13ik2vFPPvcvncdGMCzeCWlmUy4m2LvbUt034vbypqGtFhLDu/1A62NE9xqC7rNoV/k+WKbOeHNOt12KQz2Khql8GFgC/BD4JHBCRb4nIPF/PdReXfSJyUES+OMpxd4qIikixx32XichbIrJHRCpEJPpbQiPAYLgd7cUC4O4SB8dbu3hl/8SC7t7+AR7aUEnB9FQ+u8L7P+uVhbmInFvOItAq61qZnzOVKcmhDbc9Fc7M4Epn5pg7usuqGrk0fxp5k6Bre7jUpHhy0m2pcvAzs1DXv5wT7q8+YDrwRxF5ZKTniEg88BjwQWAxUCoii70clw48AGzzuC8B+B1wr6ouAVYAvf79SGY00di5PZJVRXlkT5140P3Em0fY39DBg7cuHvGae/bUZJY6MtlUHZwptBVhDLc9lZY4ea+pkx1HWvw6/lRHN7tqWibFWlAjuch6LQD/MosHRGQn8AjwBnCpqt4HXAXcMcpTS4CDqnpIVXuAp4DbvRz3dfdre7bI3gK8q6rvAKjqKVW1pR8DoCLKw21Pg0H3pupGjreOL+hubOviBxsPsGJRDjcvHv2a+6rCXN6pbaUxwN3cjW1dNIYx3PZ062WzXUH3Nv+WONmyrwlVWF00+fKKQc6sNI4122KC/pxZZAP/rKrvV9U/qGovgKoOALeO8rx8wDN9rHXfN0RErgAcqvr8sOcuBFREXhKRXSLy//gxTuOHyRBueyotcTKg8MyO8TWUfevFKnr6Bnj4tiU+m8lWuT8QN+8L7KWoYO65PVapSfF85Ip8Xqz0L+guq24gLyOZS/InR9e2N46sNOpbz9LTN3lXO/aHP58YLwJDk69FJF1ErgZQ1apRnuft/7yhC6EiEgd8H/i8l+MSgOuBj7n//IiIrLrgDUTuEZFyESlvagrNSqTRzLUsefSH255cQXc2T++ooX9gbDOVth06xbNv1/OZ5RczJ/vCUHu4wpnp5GemBnwKbSSE257WLXPS0zfAn3fXjXpcT98Ar+4/6c5zJu+8l6Glyif5xlu++FMsfgJ0eNzudN/nSy3g8LhdANR73E4HLgG2iMgR4BpggzvkrgVeUdWTqnoGV8G6cvgbqOrjqlqsqsU5OTl+DCm2HZlE4banu0uc1Ld28cp+/z/Ee/sHePC5PeRnpvLZFfP9eo6IsLIwl9cPBLabe7BzO5zhtqfFszNY6vAddG8/3ExHd9+kWWV2JDZ91sWfYiHq8S/GffnJn3/VO4AFIjJXRJKAdcAGj9dpVdVsVZ2jqnOArcAaVS0HXgIuE5E0d9i9HNjr909lvBq83BEJ18YDafViV9D95Db/ey5+89ZR9jW08+Bti0lN8r+RbFVRLmd7+3nr0KnxDNWrd2sjI9z2dPfVTg42dlB+dOSge2NVA8kJcVw3f3J1bQ9njXku/hSLQ+6QO9H99W/AIV9PUtU+4H5cH/xVwDOqukdEviYia3w8twX437gKztvALlV9wY+xmlFU1LaSlBDHgrzoD7c9JcbHcVdxAZuqGzjR6jt8bmzv4gcv72f5whxu8RFqD3fNxTNIS4oP2MKCkRRue7r1slmkJ4+8dLmra7uB6+Znj6nYRqOcqa6lymO918KfYnEvcC1Qh+vy0NXAPf68uKq+qKoLVXWeqn7Tfd+DqrrBy7Er3GcVg7d/p6pLVPUSVbWAOwAGw+3ESRJueypd5gq6/dmj+9svVtPdN8DDa3yH2sOlJMZz/fzsgHVzh2rP7bFKS0rgw1fk80LFcU6fuTDoPtjYwbHms5OyEW+4uDjBkZVGTYyvPutPU16jqq5T1VxVzVPVu1U1+Iv7m4A6F25HRogaaM4Z/gXd2w838+fdddxz48XM9SPU9mZ1UR71rV1UHW8f73CHDIbbkbgHRGmJO+jedWHQvXES7bXtD2dWGkftzGJ0IpIiIp8TkR+LyK8Gv0IxOBM4kzXc9lTqDrpfHaGju69/gAefqyQ/M5XP3eRfqO3NikLXZIpAXIqqrGvl4uwpERNue1o8O4PLRwi6y6oaWDI7g1nTUsM0utBy2lLlfl2G+i2u9aHeD7yCa1bTxH+lMiE1WcNtT6uL8siemjTiyqm/3XqU6hPtfOXWogldZ89NT+FyRyYbA7B7XkVdK5cVZE74dYLl7hIHBxo72OkRdDd39rCrpmWo7yQWOLLS6Ojuo+VM7C4k4U+xmK+qXwE6VfUJ4J+AS4M7LBNolXWucHthXnq4hxI0SQlx3HmVg03VjRcE3Y3tXfzvf+znhgXZvH/JzAm/1+rCXN45dpqm9u5xv0ZjexcNbZEXbnu67fLZTB0WdG/Z18iAujraY4XNiPKvWAyW0tMicgkwDZgTtBGZoJjM4ban0hIH/QN6wdLl3/5bNV19/Xx1HKG2Nyvdwe7mCZxdRMMmVK6gezbPewTdZVWN5KQnR/S4A82KhX/F4nH3fhZfxtUnsRf4z6COygTUwICyp27yhtueLpoxhevnZ/P0jmNDQXf5kWb+vKuOT99wMRfnBGba8OJZGcyeljK0PPd4VNS2RWy47Wkw6P7L7jp313YTqwpziYubvF3bwzmyXNlMLE+fHbVYuJfkaFPVFlV9VVUvds+K+lmIxmcC4GjzGdonebjtqbTESd3ps7x6oIm+/gG+8tweZk9L4f6V4w+1hxMRVhbl8toEurkrIjjc9rRk9jQuL5jG+u017DjSTHt3X8zMghqUlpRA9tTkmJ4+O2qxcHdr3x+isZggiYVw29PNi/OYMSWJ9dtq+N3Wo1Qdb+Mrty4mLSmwH8qrCvM409PP1nF2c1fUnY6aAl5a4mR/Qwff/cc+khLiuH7B5O7a9saZlWqXoXx4WUS+ICIOEcka/Ar6yEzAVNSenvThtqekhDjuLC6grLqR77lD7Q9cMvFQe7j3zZtBamI8m8aRW0RDuO1pMOjeXXOaa+fNCHjhjQbOGN/Xwp9i8S/A54BXgZ3ur/JRn2EiSkVdK0Uz0yd9uO2pdJmT/gGlq69/XJ3a/khJjOf6BdmUjaObOxrCbU9TkhO4felsgJiaMuvJOWMKx2N4qXKfvx6o6txQDMQEx2C4vcb9P3qsmJM9hU9dP5f8zFTmBSjU9mZVYS4v722g+kQ7RWNYYnwo3I6SYgHwP264mJrmM3woCGdp0cCZlcaAQv3ps34taT/Z+CwWIvJxb/er6m8CPxwTaLEWbnv6yq0X7OIbcINB76bqxrEVi7pW5mZPYWqEh9ue5mZP4befujrcwwgbz+mzsVgs/Lkusczj6wbgYWDUVWNN5Ii1cDvUcjNSuLxgGhvHuPRHZYTsuW38F+u9Fv5chvpXz9siMg3XEiAmCsRC53a4rSzM4wdl+znZ0U321GSfxze1d3OircuKRZTJTU8mKYaXKh9P4nkGWBDogZjgqKh1hdtJCbETbofaqqJcVP3v5o62cNu4xMUJjumxO33Wn1Vn/yoiG9xfzwP7gOeCPzQzUapKZX2rXYIKsiWzM5iZkUKZn3tzDy1Lbn8vUceZlcbRGG3M8ydd+67H933AUVWtDdJ4TAAdPXWG9q7YDLdDabCb+7nddXT39ZOcMPqKttEYbhsXZ1Ya5UdaUNWgTMeOZP5cm6gBtqnqK6r6BnBKROYEdVQmICzcDp3VRbl09vSz7VCzz2MrInDPbeMfR1Ya7d19nI7Bpcr9KRZ/ADy7UPrd95kIV1HXSlK8hduhcO28bFIS43xuiGThdnSL5RlR/hSLBFUd2oTX/X1S8IZkAqWitpXCWRZuh8Lg3txl1aNu6W0EAAATUUlEQVR3c1fa2V5Uc86wYjGaJhEZ6qsQkduBk8EbkgkEC7dDb1VRHrUtZ9nf0DHiMYOXBiN9WXLjnWN67BYLfxK2e4Hfi8ij7tu1gNeubhM5LNwOvcFu7o1VDSya6f3S3+Cy5OkpiaEcmgmQKckJZE9NisleC59nFqr6nqpeAywGlqjqtap6MPhDMxNRYXP5Qy4vI4VL86eNugptZZ2d7UU7R4yuPutPn8W3RCRTVTtUtV1EpovIN0IxODN+lRZuh8Wqolx21bRwquPCvblPdnRzvNXC7WgXyKXKy6oaeOu98e2HEmr+ZBYfVNXTgzdUtQX4UPCGZAKhos7C7XBYVZiHKmzZ13TBY0NnewVWLKKZMyuN+tNn6e0f/1LlAwPKt/9WzaeeKOdf1++e0GuFij+fJPEiMrTgjYikAr4XwDFho6p2uSNMLsnPIC8j2eve3JW1Fm5PBg6PpcrHo7O7j8/8bic/feU9rp6bxcmObjbuHf9e7qHiT7H4HVAmIp8SkU8BLwNPBHdYZiJqms/QZuF2WIgIKwvzeHX/yQs2ybFwe3K4aAK9FnWnz3LHT96krKqBr65ZwpOfvoZZ01J4cntNoIcZcP4E3I8A3wCKcIXcfwcuCvK4zARYuB1eqwpz6ejuY/vh87u5K+xsb1IYb6/FzqMt3P7o69SdPsuv/3sJn7h2DvFxwtplDl47cDLiZ1j5e0H7BK4u7juAVUBV0EZkJsw6t8PruvnZJCfEnbfHhYXbk0deegpJ8XFjKhZ/2V1L6eNbmZKcwF8+ex3LF+YMPbZ2mYM4gad2RPbZxYjFQkQWisiDIlIFPAocA0RVb1LVR0d6ngm/itpWFtmy5GGTmjTYzd0w1M1t63RNHnFxQkFWql9nAgMDyndequbfn36HKy/K5NnPXsf83PO3+Z01LZWVhbk8U14b0UH3aJ8m1bjOIm5T1etV9Ue41oUyEczC7ciwsiiXY81nOdjo6uYeCrfzLdyeDPyZPtvZ3cd9v9/JY5vfo7TEwW/+5WqmT/G+UlJpiZOm9m6fa4uF02jF4g5cl582i8jPRWQVEFtr8kYhC7cjw6rCPAA2uve4GFyWPMPC7UlhcF+LkdYBqz99lrt++hYv723gwVsX862PXDrqmf7yhTnuoPtYsIY8YSOOXlX/oqprgUJgC/DvQJ6I/EREbgnR+MwYWbgdGWZOS+GS/Aw2uafQ2tne5OLMSqO9q4/WsxcuVb67poU1j77BseYz/PKTy/iX6+f63PsiIT6OjxY7eO1AU8QG3f7MhupU1d+r6q1AAfA28MWgj8yMS0VdK4nxwsKZU30fbIJqZWEeO4+2cLCxg/rWLi61S1CThmOE6bPPvV3H2se3kpYUz58/ey03Lcr1+zXXLnMgwNM7IvPsYkwJqKo2q+rPVHVlsAZkJqayzhVu+9qtzQTf6qJcBhQe3XQAsHB7Mhm+r8XAgPK9f+zj3556m6WOTJ793HUsGONsxNmZqdy0KJeny49FZNBt02UmEVe43cal+ZnhHooBLpk9jdz0ZDa8U++6bcVi0vA8szjT08fnntzFjzYd5KPFBfzuU1eTNUKQ7cu5oNu//dxDyYrFJHKs+SytZ3str4gQcXHCykLX2YWF25PL1OQEZkxJYueRFj76s7f4+54TfPmfivjPOy6b0JT1FYtymJmRwvoI7OgO6o7xIvIB4IdAPPALVf32CMfdiWur1mWqWu5xvxPYCzysqt8N5ljDraWzh+crjtM3gdPPA+5pmlYsIseqojye2nHMziomIUdWGmXVjUxJiueXnyhmpXsG3EQkxMfx0WUOfrTpAMeazwydwUSCoBULEYkHHgNuxrVh0g4R2aCqe4cdlw48AGzz8jLfB/4WrDFGiv0N7XzqiR0cax7fwmSesqcmW7gdQa6bP4Pc9GRuXJAd7qGYALv64izazvbyk/921YibXY3H2mUOHt10gGfKj/H5WxYF7HUnKphnFiXAQVU9BCAiTwG34zpT8PR14BHgC553isiHgUNAZxDHGHabqxv51/W7SU2K55nPvI+FeRP7oE9NirdwO4KkJSWw7X+t8jl10kSfL36gkC99sCjgr5ufmcqKRbk8veMYD6xaQGJ8ZKQFwSwW+biWCBlUC1zteYCIXAE4VPV5EfmCx/1TgP/AdVZyXhGZLFSVX75+mG+9WEXhzAx+8YliZmemhntYJgisUExOwfx7LS1x8unflLOpupH3L5kZtPcZi2CWLG//JYfaHUUkDtdlps97Oe6rwPdVtWPUNxC5R0TKRaS8qenCzWYiVU/fAP/rLxV844Uqbl6cxx/ve58VCmPMkJsW5ZCXkRxRQXcwzyxqAYfH7QKg3uN2OnAJsMVdoWcCG0RkDa4zkDtF5BEgExgQka7hCxiq6uPA4wDFxcXe++4jTEtnD/f+bifbDjfzuZvm8fmbFxEXZ795GmPOSYiPY22xgx9tPkhtyxkKpoc/6A7mmcUOYIGIzBWRJGAdsGHwQVVtVdVsVZ2jqnOArcAaVS1X1Rs87v8B8K3JsNLtwcZ2PvzjN9h97DTfX3s5//P9hVYojDFefXSZ63ftZyKkoztoxUJV+4D7gZdw7X/xjKruEZGvuc8eYsor+5v4yGNv0tndx/pPX8NHrigI95CMMRGsYHoaKxbm8HT5sQlNqQ+UoPZZqOqLwIvD7ntwhGNXjHD/wwEfWAipKk+8eYSvPb+XhXnp/OITxRFxSmmMiXylJU7u+e1ONlU3ckuYg+7ImJM1SfX2D/D/PlvJw3/dy6qiPP5037VWKIwxfltZmEtuemQE3VYsguT0mR4+8avtPLmthvtWzONn/+0qpiQH9UTOGDPJJMTHsXaZgy37m6g7PfGm3YmwYhEE7zV18OHH3qD8SAvfu+ty/uMDFmQbY8ZnrTvoDvfS5VYsAuy1A018+LE3aO/q48lPX80dV1mQbYwZv4LpaSxfmMPTO2rCGnRbsQig37x1hE/+egf5mak8+7nrKJ6TFe4hGWMmgdISJw1t3WzeF77mYysWAdA/oHzl2UoefG4PKxbm8Mf7ro2o1SKNMdEtEoJuKxYB8ELFcX679SifvmEuj3+8mKkWZBtjAijRvUf3ln2NYQu6rVgEwMt7G8iemsSXPlhEvAXZxpggWLvMgRK+jm4rFhPU2z/AK/sauWlRrs14MsYEjSMrjRsX5PD0jvB0dFuxmKDyIy20dfWxqmjiu2QZY8xoSkucnGjrYksYgm4rFhNUVtVAUnwcN9hOaMaYIFtVlEtOmIJuKxYTtKm6kWvmzbDubGNM0LmC7gI272ukPsRBtxWLCTjU1MGhk52sLsoN91CMMTFi3TKnK+guD23QbcViAsqqGgHXHGhjjAkFR1YaN4Qh6LZiMQFl1Q0Uzky3lWSNMSF1d4mD461dvLI/dEG3FYtxaj3Ty44jLayyS1DGmBBbVZRH9tTQBt1WLMZpy/5G+geUlYU2ZdYYE1qDQfem6kaOt4Ym6LZiMU6bqhuZMSWJpY7McA/FGBOD1i1zMqDwzI7akLyfFYtx6OsfYMu+JlYsyrXlPYwxYeGckcYNC7J5ekcN/QMa9PezYjEO5UdbaD3ba1NmjTFhdXeJk/rWLl7Z3xj097JiMQ6bqhtJjBduWJgT7qEYY2LY6sWuoPvJbcHvubC243HYWNXANRfPsKXIjTFhlRgfx/c+ejlzZgR/+r592o3R4ZOdHGrq5OPXXBTuoRhjDMtDdIXDLkONUVlVA4CtMmuMiSlWLMaorKqRhXlTbdtUY0xMsWIxBq1ne9lxpNnOKowxMceKxRi8ur+JvgG1KbPGmJhjxWIMyqoayJqSxFLH9HAPxRhjQsqKhZ/6+gfYsr+JFYtyrGvbGBNzrFj4aVfNaU6f6WWVLRxojIlBViz8VFbVQGK8cONC22vbGBN7rFj4qay6kavnziA9JTHcQzHGmJCzYuGHo6c6OdjYYdunGmNilhULP2x077W92vorjDExyoqFHzZVN7AgdyrOECzWZYwxkciKhQ9tXb1sO9TMSmvEM8bEsKAWCxH5gIjsE5GDIvLFUY67U0RURIrdt28WkZ0iUuH+c2Uwxzmac13bdgnKGBO7grZEuYjEA48BNwO1wA4R2aCqe4cdlw48AGzzuPskcJuq1ovIJcBLQH6wxjqaTVWNZKYlcqXTuraNMbErmGcWJcBBVT2kqj3AU8DtXo77OvAI0DV4h6ruVtV69809QIqIJAdxrF71Dyib9zVyk+21bYyJccEsFvmA515/tQw7OxCRKwCHqj4/yuvcAexW1e7AD3F0u2paaDnTyyrLK4wxMS6YO+V5+1Vchx4UiQO+D3xyxBcQWQL8J3DLCI/fA9wD4HQ6JzBU78qqGkmIE260vbaNMTEumGcWtYDD43YBUO9xOx24BNgiIkeAa4ANHiF3AfAX4OOq+p63N1DVx1W1WFWLc3IC/4FeVtVAydwsMqxr2xgT44JZLHYAC0RkrogkAeuADYMPqmqrqmar6hxVnQNsBdaoarmIZAIvAF9S1TeCOMYR1Zw6w4HGDtvoyBhjCGKxUNU+4H5cM5mqgGdUdY+IfE1E1vh4+v3AfOArIvK2+yukwUFZtXuvbVviwxhjgppZoKovAi8Ou+/BEY5d4fH9N4BvBHNsvpRVNTIvZwpzsqeEcxjGGBMRrIPbi/auXrYdPmWNeMYY42bFwovXDpykt19tlVljjHGzYuHFxqoGpqUmctVF1rVtjDFgxeIC/QPKln1N3LQoh4R4+89jjDFgxeICbx9robmzh5WWVxhjzBArFsNsdHdtL7eubWOMGWLFYphNVY0sm5PFtFTr2jbGmEFWLDwcaz7DvoZ2WzjQGGOGsWLhoazK3bVteYUxxpzHioWHsupGLs6ewlzr2jbGmPNYsXDr6O5j26FmuwRljDFeWLFwe21/Ez39A3YJyhhjvLBi4VZW3UhGSoJ1bRtjjBdWLHDvtV3dyIpFuSRa17YxxlzAPhmBt4+d5lRnj+UVxhgzAisWwKbqBuLjhBULrVgYY4w3VixwbXRUfNF0pqVZ17YxxngT88WituUM1SfabaMjY4wZRcwXi67efm5enGd5hTHGjCKoe3BHg/m56fz848XhHoYxxkS0mD+zMMYY45sVC2OMMT5ZsTDGGOOTFQtjjDE+WbEwxhjjkxULY4wxPlmxMMYY45MVC2OMMT6JqoZ7DAEhIk3A0XCPwxhjosxFqprj66BJUyyMMcYEj12GMsYY45MVC2OMMT5ZsTBRQURURL7ncfsLIvJwgF77v0TkzkC8lo/3uUtEqkRks5fHviMie0TkO+N43aUi8qHAjNIY76xYmGjRDfyziGSHeyCeRCR+DId/Cvisqt7k5bHPAFeq6v8cxzCWAmMqFuJi//8bv9k/FhMt+oDHgX8f/sDwMwMR6XD/uUJEXhGRZ0Rkv4h8W0Q+JiLbRaRCROZ5vMxqEXnNfdyt7ufHu3/j3yEi74rIZzxed7OIPAlUeBlPqfv1K0XkP933PQhcD/x0+NmDiGwApgDbRGStiOSIyJ/c77tDRK5zH1ciIm+KyG73n4tEJAn4GrBWRN52P/9hEfmCx+tXisgc91eViPwY2AU4ROQWEXlLRHaJyB9EZKr7Od8Wkb3un/u7Y/3LMpOQqtqXfUX8F9ABZABHgGnAF4CH3Y/9F3Cn57HuP1cAp4FZQDJQB3zV/di/AT/weP7fcf3ytACoBVKAe4Avu49JBsqBue7X7QTmehnnbKAGyMG1X8wm4MPux7YAxSP9fB7fPwlc7/7eCVS5v88AEtzfrwb+5P7+k8CjHs9/GPiCx+1KYI77awC4xn1/NvAqMMV9+z+AB4EsYB/nZktmhvvv377C/xXzmx+Z6KGqbSLyG+AB4KyfT9uhqscBROQ94B/u+ysAz8tBz6jqAHBARA4BhcAtwGUeZy3TcBWTHmC7qh728n7LgC2q2uR+z98DNwLP+jlecBWCxSIyeDtDRNLd7/+EiCwAFBjPpvFHVXWr+/trgMXAG+73SgLeAtqALuAXIvIC8Pw43sdMMlYsTLT5Aa5LKL/2uK8P9yVVcX3qJXk81u3x/YDH7QHO//c/vOFIAQH+VVVf8nxARFbgOrPwRka4fyzigPep6nkFUUR+BGxW1Y+IyBxcZyreDP33cEvx+N5z3AK8rKqlw19AREqAVcA64H5g5dh+BDPZWGZhooqqNgPP4AqLBx0BrnJ/fzvj+437LhGJc+cYF+O6DPMScJ+IJAKIyEIRmeLjdbYBy0Uk2x1+lwKvjHEs/8D1AY37fZe6v52G61IauC49DWoH0j1uHwGudD/3SlyXzrzZClwnIvPdx6a5f8apwDRVfRH4v3AF6CbGWbEw0eh7uK63D/o5rg/o7cDVjPxb/2j24fpQ/xtwr6p2Ab8A9gK7RKQS+Bk+zsbdl7y+BGwG3gF2qepzYxzLA0CxO1zeC9zrvv8R4P8TkTcAz1lYm3FdtnpbRNYCfwKyRORt4D5g/whjbcJVdNaLyLu4ikchrsLzvPu+V/AyqcDEHlvuwxhjjE92ZmGMMcYnKxbGGGN8smJhjDHGJysWxhhjfLJiYYwxxicrFsYYY3yyYmGMMcYnKxbGGGN8+j+m0ET/teqCxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a value for k that gets us result for validation data, we can use it to finally test our model on testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Testing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48756218905472637"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k = best_accuracy_loc * 5).fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "ensemble(X_train, X_test, y_train, y_test)\n",
    "# Produces a test accuracy of >45%, which is better than the model with an untuned value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
